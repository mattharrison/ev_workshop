{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effective Visualization Workshop\n",
    "\n",
    "(C) 2025 - MetaSnake\n",
    "\n",
    "*Outline*\n",
    "\n",
    "- Appreciating Plots\n",
    "- CLEAR Methodology\n",
    "- Line Plots\n",
    "- Bar Plots\n",
    "- Scatter Plots\n",
    "- Histograms\n",
    "- Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appreciating Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Line Plots\n",
    "| Image | Image | Image |\n",
    "| --- | --- | --- |\n",
    "| <small>https://x.com/ianbremmer/status/1846276776802074902</small> <br> Econnomist <br> <img src='https://pbs.twimg.com/media/GZ9K7WtW8AAfXbq?format=png&name=900x900' width=200> | https://x.com/jburnmurdoch/status/1775658270855741763 <br> Financial Times <br> <img src='https://pbs.twimg.com/media/GKRnfPLWkAA8rXh?format=jpg&name=4096x4096' width=200> | https://x.com/mpolikoff/status/1767560868420862332 <br> Econonmist <br> <img src='https://pbs.twimg.com/media/GIejIxUa0AAmerB?format=png&name=small' width=200> |\n",
    "| https://x.com/ianbremmer/status/1766229005554814994 <br> NY Times <br> <img src='https://pbs.twimg.com/media/GILn51NW0AApTlp?format=jpg&name=large' width=200> | https://x.com/RishiJoeSanu/status/1663456933452578816<br> Our World in Data <br> <img src='https://pbs.twimg.com/media/FxXJQ_laIAAG0SJ?format=jpg&name=900x900' width=200> | https://x.com/WaltHickey/status/1712840003053646290 <br> Walter Hickey <br> <img src='https://pbs.twimg.com/media/F8U6512WkAAWrtW?format=jpg&name=large' width=200> |\n",
    "| https://www.dontusethiscode.com/blog/2024-10-09_plotting_timeseries.html <br> DUTC <br> <img src='https://www.dontusethiscode.com/_images/a7a3313140660cc873a7415b6c0202b6cba2981b13562fcaceb6687ca66513d9.png' width=200> | https://x.com/RoverSportMike/status/1699234790308794536 <br> Economist <br> <img src='https://pbs.twimg.com/media/F5S22HSXEAEom87?format=png&name=small' width=200> | https://blog.datawrapper.de/color-keys-for-data-visualizations/ <br> Datawrapper Blog <br> <img src='https://blog.datawrapper.de/wp-content/uploads/2023/07/Screenshot-2023-07-20-at-16.53.14.png' width=200> |\n",
    "|   | https://x.com/danz_68/status/1659470392640012293 <br> Daniel Zvinca <br> <img src='https://pbs.twimg.com/media/FweffwOXsAAZJym?format=jpg&name=4096x4096' width=200> | https://datawookie.dev/blog/2019/07/recreating-unknown-pleasures-graphic/ <br> <img src='https://github.com/datawookie/data-diaspora/raw/master/pulsar-joy-division-unknown-pleasures.jpg' width=200> |\n",
    "| https://x.com/Bengass/status/1657049892986945536 <br> Economist <br> <img src='https://pbs.twimg.com/media/Fv8GGKfXwAIeC0r?format=jpg&name=medium' width=200> | https://www.dataquest.io/blog/making-538-plots/ <br> <img src='https://www.dataquest.io/wp-content/uploads/2019/01/538_graphs_AO_29_1.png' width=200> | https://x.com/artificialnix/status/1543355720111984640 <br> Our World in Data <br> <img src='https://pbs.twimg.com/media/FWsZ2MYX0AkwTCL?format=jpg&name=large' width=200> |\n",
    "| https://x.com/DanielleFong/status/1471206421819760640 <br> <img src='https://pbs.twimg.com/media/FGrGcCKXEAwmxFv?format=jpg&name=large' width=200> | https://x.com/antgoldbloom/status/1415334581021024258 <br> Our world in data <br> <img src='https://pbs.twimg.com/media/E6RHGhLVcAEqt5m?format=jpg&name=large' width=200> | https://blog.datawrapper.de/data-vis-dispatch-august-27-2024/ <br> guardian <br> <img src='https://blog.datawrapper.de/wp-content/uploads/2024/08/image9-2-1094x2048.png' width=200> | \n",
    "| https://blog.datawrapper.de/data-vis-dispatch-july-23-2024/ <br> Square edges <br> <img src='https://blog.datawrapper.de/wp-content/uploads/2024/07/image25-1.png' wdith=200> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Plots\n",
    "\n",
    "| Image | Image | Image |\n",
    "| --- | --- | --- |\n",
    "| https://x.com/AlexSelbyB/status/1745513524523086131 <br> Economist <br> <img src='https://pbs.twimg.com/media/GDlNsnCWIAE0VRW?format=png&name=small' width=200> | ` https://medium.com/@addtwo/rule-18-dont-use-multi-coloured-bars-60b265f8a620 ` <br> <img src='https://miro.medium.com/v2/resize:fit:4800/format:webp/0*10FEHG4OKw7-7XN1' width=200> | https://www.dontusethiscode.com/blog/2023-09-13_dib_recreate_usjets.html <br> DUTC <br> <img src='https://preview.redd.it/business-jet-demand-in-north-america-v0-tnf4rahjcilb1.png?auto=webp&s=01f388465b6e603fe40e2b6faffb6c4ce8d6f753' width=200> | \n",
    "| https://blog.datawrapper.de/data-vis-dispatch-september-10-2024/ <br> <img src='https://blog.datawrapper.de/wp-content/uploads/2024/09/image23-1.png' width=200> | https://blog.datawrapper.de/data-vis-dispatch-august-27-2024/ <br> <img src='https://blog.datawrapper.de/wp-content/uploads/2024/08/image6-5.png' width=200> | Wall Street Journal <br> https://blog.datawrapper.de/data-vis-dispatch-august-13-2024/ <br><img src='https://blog.datawrapper.de/wp-content/uploads/2024/08/image25.png' width=200> |\n",
    "| https://blog.datawrapper.de/data-vis-dispatch-july-30-2024/ <br> Economist <br> <img src='https://blog.datawrapper.de/wp-content/uploads/2024/07/image10-3-1408x2048.png' width=200> | https://blog.datawrapper.de/data-vis-dispatch-july-30-2024/ <br> <img src='https://blog.datawrapper.de/wp-content/uploads/2024/07/image16-3.png' width=200> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plots\n",
    "\n",
    "| Image | Image | Image |\n",
    "| --- | --- | --- |\n",
    "| https://x.com/StefanFSchubert/status/1765442124948951336 <br>Our World in Data <br> <img src='https://pbs.twimg.com/media/GIAcQZSWoAEy-9v?format=jpg&name=large' width=200> | https://blog.datawrapper.de/emphasize-with-color-in-data-visualizations/ <br> <img src='https://lh4.googleusercontent.com/3pIZgrdZgMZLszq3rPHeiFduRxUQdYxWZOMylO_IpKIQ7wg4aCe7Y11MzNPUzEOjcq29hRXkSfg5HKpm_Ycs3fUuv0aogX-yNAX8hw230T_mYgflEzkjjyYAWqg7MeMHu4M4jPLrEG424ol8g9OnWRE' width=200>| https://www.atlassian.com/data/charts/what-is-a-scatter-plot <br> <img src='https://wac-cdn.atlassian.com/dam/jcr:6a10e325-fdfb-41a2-96da-a66e29b99847/scatter-plot-example-2.png?cdnVersion=2361' width=200> |\n",
    "| https://www.practicedataviz.com/index.html <br> https://www.idlewyldanalytics.com/chapters/PDV-5.pdf |\n",
    "| https://blog.datawrapper.de/data-vis-dispatch-october-12-2021/ <br> <img src='https://blog.datawrapper.de/wp-content/uploads/2021/10/data-vis-dispatch-visualization9.png' width=200> | https://blog.datawrapper.de/data-vis-dispatch-september-17-2024/ <br> NY Times <br> <img src='https://blog.datawrapper.de/wp-content/uploads/2024/09/image6-2.png' width=200> | countries with a higher GDP tend to win more medals <br> https://blog.datawrapper.de/data-vis-dispatch-august-13-2024/ <br> <img src='https://blog.datawrapper.de/wp-content/uploads/2024/08/image14.png' width=200> | \n",
    "| https://blog.datawrapper.de/data-vis-dispatch-july-30-2024/ <br> Economist <br> <img src='https://blog.datawrapper.de/wp-content/uploads/2024/07/image11-1.png' width=200> | https://blog.datawrapper.de/data-vis-dispatch-july-23-2024/ <br> <img src='https://blog.datawrapper.de/wp-content/uploads/2024/07/image22-2.png' width=200> |\n",
    "| https://x.com/Sondreus/status/1859599631904100389/photo/1 Economist <br> <img src='https://pbs.twimg.com/media/Gc6fGUjXsAAGSiI?format=jpg&name=medium' width=200> | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAR Methodology\n",
    "\n",
    "- **C**olor\n",
    "- **L**imited Plot Types\n",
    "- **E**xplain (title, subtitle, annotations)\n",
    "- **A**udience\n",
    "- **R**efeference (source at the bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Plots\n",
    "\n",
    "Let's recreate the following line plot\n",
    "\n",
    "World in Data <br> <img src='https://pbs.twimg.com/media/FWsZ2MYX0AkwTCL?format=jpg&name=large' width=600> |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "url = 'https://github.com/mattharrison/datasets/raw/refs/heads/master/data/owid-spending-vs-lifeexp.csv'\n",
    "raw_owid = pd.read_csv(url, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_owid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spending per country per year\n",
    "(raw_owid\n",
    " .groupby(['TIME','LOCATION'])\n",
    " ['Spending_USD']\n",
    " .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spending per country per year\n",
    "(raw_owid\n",
    " .groupby(['TIME','LOCATION'])\n",
    " ['Spending_USD']\n",
    " .sum()\n",
    " .unstack()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spending per country per year\n",
    "(raw_owid\n",
    " .groupby(['TIME','LOCATION'])\n",
    " ['Spending_USD']\n",
    " .sum()\n",
    " .unstack()\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move legend\n",
    "ax = (raw_owid\n",
    " .groupby(['TIME','LOCATION'])\n",
    " ['Spending_USD']\n",
    " .sum()\n",
    " .unstack()\n",
    " .plot()\n",
    ")\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=2, fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix country names and add continents\n",
    "raw_owid.LOCATION.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_info = {\n",
    "    'AUT': ('Austria', 'Europe'),\n",
    "    'BEL': ('Belgium', 'Europe'),\n",
    "    'CHE': ('Switzerland', 'Europe'),\n",
    "    'DEU': ('Germany', 'Europe'),\n",
    "    'ESP': ('Spain', 'Europe'),\n",
    "    'FIN': ('Finland', 'Europe'),\n",
    "    'FRA': ('France', 'Europe'),\n",
    "    'GBR': ('United Kingdom', 'Europe'),\n",
    "    'IRL': ('Ireland', 'Europe'),\n",
    "    'ISL': ('Iceland', 'Europe'),\n",
    "    'JPN': ('Japan', 'Asia'),\n",
    "    'KOR': ('South Korea', 'Asia'),\n",
    "    'NOR': ('Norway', 'Europe'),\n",
    "    'NZL': ('New Zealand', 'Oceania'),\n",
    "    'PRT': ('Portugal', 'Europe'),\n",
    "    'SWE': ('Sweden', 'Europe'),\n",
    "    'USA': ('United States', 'North America'),\n",
    "    'AUS': ('Australia', 'Oceania'),\n",
    "    'CAN': ('Canada', 'North America'),\n",
    "    'DNK': ('Denmark', 'Europe'),\n",
    "    'NLD': ('Netherlands', 'Europe'),\n",
    "    'TUR': ('Turkey', 'Europe'),\n",
    "    'LUX': ('Luxembourg', 'Europe'),\n",
    "    'GRC': ('Greece', 'Europe'),\n",
    "    'ITA': ('Italy', 'Europe'),\n",
    "    'CZE': ('Czech Republic', 'Europe'),\n",
    "    'POL': ('Poland', 'Europe'),\n",
    "    'HUN': ('Hungary', 'Europe'),\n",
    "    'ISR': ('Israel', 'Asia'),\n",
    "    'SVK': ('Slovakia', 'Europe'),\n",
    "    'EST': ('Estonia', 'Europe'),\n",
    "    'MEX': ('Mexico', 'North America'),\n",
    "    'CHL': ('Chile', 'South America'),\n",
    "    'LTU': ('Lithuania', 'Europe'),\n",
    "    'SVN': ('Slovenia', 'Europe'),\n",
    "    'LVA': ('Latvia', 'Europe'),\n",
    "    'BGR': ('Bulgaria', 'Europe'),\n",
    "    'ROU': ('Romania', 'Europe'),\n",
    "    'HRV': ('Croatia', 'Europe'),\n",
    "    'BRA': ('Brazil', 'South America'),\n",
    "    'CHN': ('China', 'Asia'),\n",
    "    'COL': ('Colombia', 'South America'),\n",
    "    'CRI': ('Costa Rica', 'North America'),\n",
    "    'IND': ('India', 'Asia')\n",
    "}\n",
    "\n",
    "def get_continent(country):\n",
    "    # map real country names to country codes\n",
    "    mapping = {v[0]:v[1] for k,v in country_info.items()}\n",
    "    return mapping[country]\n",
    "\n",
    "colors = []\n",
    "def calc_colors(df):\n",
    "    global colors\n",
    "    cmap = plt.cm.get_cmap('tab20')\n",
    "    continent_colors = {'North America': cmap(0), 'Europe': cmap(1), \n",
    "                        'Asia': cmap(2), 'Oceania': cmap(3), 'South America': cmap(4),\n",
    "                        'Africa': cmap(5)\n",
    "                        }\n",
    "\n",
    "    colors = [continent_colors[get_continent(country)] for country in df.columns]\n",
    "    return df\n",
    "\n",
    "ax = (raw_owid\n",
    "    .groupby(['TIME','LOCATION']) \n",
    "    ['Spending_USD']\n",
    "    .sum()\n",
    "    #.reset_index()\n",
    "    .unstack()\n",
    "    # sort columns by continent\n",
    "    .loc[:, lambda df_: sorted(df_.columns, key=lambda col: country_info[col][1])]\n",
    "    # rename columns\n",
    "    .rename(columns=lambda col: country_info[col][0])\n",
    "    # set colors\n",
    "    .pipe(calc_colors)\n",
    "    .plot(color=colors)\n",
    ")\n",
    "\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=2, fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is melted\n",
    "# try to plot spending per country vs life expectancy\n",
    "(raw_owid\n",
    " .plot(x='Spending_USD', y='Life_Expectancy')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try groupby\n",
    "ax = (raw_owid\n",
    " .groupby('LOCATION')\n",
    " .apply(lambda df_: df_.plot(x='Spending_USD', y='Life_Expectancy'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot on same axes\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "_ = (raw_owid\n",
    " .groupby('LOCATION')\n",
    " .apply(lambda df_: df_.plot(x='Spending_USD', y='Life_Expectancy', ax=ax), include_groups=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import highlight_text as ht\n",
    "\n",
    "font = 'Roboto Condensed'\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "groups = (raw_owid\n",
    "          # add country name\n",
    "            .assign(Country=lambda df_: df_['LOCATION'].map(lambda x: country_info[x][0]))\n",
    "          .groupby('Country')\n",
    ")\n",
    "\n",
    "for name, group in groups:\n",
    "    if name == 'United States':\n",
    "        color = 'red'\n",
    "        linewidth = 2\n",
    "        label_fontsize = 8\n",
    "        alpha = 1\n",
    "        # label every 5th year in red\n",
    "        for i, row in group.iterrows():\n",
    "            if row['TIME'] % 5 == 0:\n",
    "                ax.text(row['Spending_USD']+500, row['Life_Expectancy'] - .25, \n",
    "                        row['TIME'], color='red', font=font, fontsize=6)\n",
    "                # draw red dot\n",
    "                ax.scatter(row['Spending_USD'], row['Life_Expectancy'], color='red')\n",
    "    else:\n",
    "        color = 'grey'\n",
    "        linewidth = 1\n",
    "        label_fontsize = 6\n",
    "        alpha = 0.5\n",
    "    ax.plot(group['Spending_USD'], group['Life_Expectancy'], \n",
    "            label=name, color=color, linewidth=linewidth, alpha=alpha)\n",
    "    # label last point\n",
    "    ax.text(group['Spending_USD'].iloc[-1], group['Life_Expectancy'].iloc[-1], name, \n",
    "            font=font, fontsize=label_fontsize)\n",
    "\n",
    "# get rid of spines\n",
    "for side in ['top', 'right', 'left', 'bottom']:\n",
    "    ax.spines[side].set_visible(False)\n",
    "\n",
    "# get rid of ticks\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "# set x ticks by 2k\n",
    "ax.set_xticks(np.arange(0, 13_000, 2_000))\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "ax.xaxis.set_major_formatter(FuncFormatter(lambda x, _: f'${x/1000:,.0f}k'))\n",
    "\n",
    "# set y ticks to 70, 75, 80, 85\n",
    "y_ticks = range(70, 85, 2)#[70, 75, 80, 85]\n",
    "ax.set_yticks(y_ticks)\n",
    "# set y limits (w/ some breathing room)\n",
    "ax.set_ylim(min(y_ticks)-1, max(y_ticks)+1)\n",
    "\n",
    "# set axis labels\n",
    "ax.set_xlabel('Healthcare Spending (USD)', font=font, fontsize=8)\n",
    "ax.set_ylabel('Life Expectancy (years)', font=font, fontsize=8)\n",
    "# set tick label font and size\n",
    "for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "    label.set_fontname(font)\n",
    "    label.set_fontsize(6)\n",
    "\n",
    "\n",
    "# add title and subtitle with highlight_text\n",
    "ht.fig_text(fig=fig, x=0.1, y=0.95, ha='left', \n",
    "            s='Life Expectancy vs Healthcare Spending\\n<US>< likes to spend>', font=font,\n",
    "            highlight_textprops=[{'color': 'red', 'fontsize':10},\n",
    "                                    {'color': 'black', 'fontsize':10}], fontsize=12)\n",
    "                                  \n",
    "# add source\n",
    "ht.fig_text(fig=fig, x=0.1, y=0.02, ha='left',\n",
    "            s='Source: Our World in Data', font=font, fontsize=6)                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Plots\n",
    "\n",
    "Great for aggregationsâ€”which is often the story that your boss wants to hear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strava data\n",
    "strava_csv_string = 'year,cycling,ebikeride\\n2016,26981.732,\\n2017,5572.5083,\\n2018,5883.0884,\\n2019,14222.912,\\n2020,668791.94,\\n2021,413450.94,\\n2022,479097.4,\\n2023,443997.88,78663.266\\n2024,117095.24,1303541.4\\n'\n",
    "from io import StringIO\n",
    "strava = pd.read_csv(StringIO(strava_csv_string))\n",
    "strava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(strava\n",
    " .set_index('year')\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Feedback:*\n",
    "> Matt, I must say that as for someone who's about to publish a book on \n",
    "> effective visualisation, you could have sprinkled a bit more awesomeness \n",
    "> on this plot ;).\n",
    "\n",
    "https://x.com/pawjast/status/1886166016587116827"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprinkle some awesomeness\n",
    "# convert meters to miles\n",
    "\n",
    "def meters_to_miles(meters):\n",
    "    return meters * 0.000621371\n",
    "\n",
    "(strava\n",
    "  .assign(cycling_miles=lambda df_: df_['cycling'].map(meters_to_miles),\n",
    "          ebikeride_miles=lambda df_: df_['ebikeride'].map(meters_to_miles))\n",
    "  .set_index('year')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(strava\n",
    "  .assign(cycling_miles=lambda df_: df_['cycling'].map(meters_to_miles),\n",
    "          ebikeride_miles=lambda df_: df_['ebikeride'].map(meters_to_miles))\n",
    "  .set_index('year')\n",
    "  .loc[2023:, ['cycling_miles', 'ebikeride_miles']]\n",
    "  .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(strava\n",
    "  .assign(cycling_miles=lambda df_: df_['cycling'].map(meters_to_miles),\n",
    "          ebikeride_miles=lambda df_: df_['ebikeride'].map(meters_to_miles))\n",
    "  .set_index('year')\n",
    "  .loc[2023:, ['cycling_miles', 'ebikeride_miles']]\n",
    "  .plot.bar()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(strava\n",
    "  .assign(cycling_miles=lambda df_: df_['cycling'].map(meters_to_miles),\n",
    "          ebikeride_miles=lambda df_: df_['ebikeride'].map(meters_to_miles))\n",
    "  .set_index('year')\n",
    "  .loc[:, ['cycling_miles', 'ebikeride_miles']]\n",
    "  .plot.bar()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strava_w_running = 'year,cycling,running,ebikeride\\n2016,26981.732,764496.56,\\n2017,5572.5083,625766.2,\\n2018,5883.0884,253411.33,\\n2019,14222.912,307388.9,\\n2020,668791.94,367890.78,\\n2021,413450.94,58778.332,\\n2022,479097.4,24614.836,\\n2023,443997.88,35664.812,78663.266\\n2024,117095.24,34825.69,1303541.4\\n'\n",
    "\n",
    "strava = pd.read_csv(StringIO(strava_w_running))\n",
    "strava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(strava\n",
    "  .assign(cycling_miles=lambda df_: df_['cycling'].map(meters_to_miles),\n",
    "          ebikeride_miles=lambda df_: df_['ebikeride'].map(meters_to_miles),\n",
    "          running_miles=lambda df_: df_['running'].map(meters_to_miles))\n",
    "  .set_index('year')\n",
    "  .loc[:, ['cycling_miles', 'ebikeride_miles', 'running_miles']]\n",
    "  .plot.bar()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, .5), dpi=300)\n",
    "\n",
    "ax.imshow(np.vstack([np.linspace(0, 1, 256), np.linspace(0, 1, 256)]),                     \n",
    "           cmap='tab20', aspect='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "color_picker = widgets.ColorPicker(\n",
    "    concise=False,\n",
    "    description='Choose a color:',\n",
    "    value='blue'\n",
    ")\n",
    "\n",
    "display(color_picker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color\n",
    "# muted for running and cycling, saturated for ebikeride\n",
    "\n",
    "color_map = {'cycling_miles': '#aec7e8',\n",
    "             'ebikeride_miles': '#2da12c', \n",
    "             'running_miles': '#fdbc79'\n",
    "             }\n",
    "(strava\n",
    "  .assign(cycling_miles=lambda df_: df_['cycling'].map(meters_to_miles),\n",
    "          ebikeride_miles=lambda df_: df_['ebikeride'].map(meters_to_miles),\n",
    "          running_miles=lambda df_: df_['running'].map(meters_to_miles))\n",
    "  .set_index('year')\n",
    "  .loc[:, ['cycling_miles', 'ebikeride_miles', 'running_miles']]\n",
    "  .plot.bar(color=[color_map[col] for \n",
    "                   col in ['cycling_miles', 'ebikeride_miles', 'running_miles']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {'cycling_miles': '#aec7e8',\n",
    "             'ebikeride_miles': '#2da12c', \n",
    "             'running_miles': '#fdbc79'\n",
    "             }\n",
    "(strava\n",
    "  .assign(cycling_miles=lambda df_: df_['cycling'].map(meters_to_miles),\n",
    "          ebikeride_miles=lambda df_: df_['ebikeride'].map(meters_to_miles),\n",
    "          running_miles=lambda df_: df_['running'].map(meters_to_miles))\n",
    "  .set_index('year')\n",
    "  .loc[:, ['cycling_miles', 'ebikeride_miles', 'running_miles']]\n",
    "  .plot.bar(width=.9, color=[color_map[col] for \n",
    "                   col in ['cycling_miles', 'ebikeride_miles', 'running_miles']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L - Limit plot - bar is good. Remove other stuff\n",
    "font = 'Roboto Condensed'\n",
    "color_map = {'cycling_miles': '#aec7e8',\n",
    "             'ebikeride_miles': '#2da12c', \n",
    "             'running_miles': '#fdbc79'\n",
    "             }\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "(strava\n",
    "  .assign(cycling_miles=lambda df_: df_['cycling'].map(meters_to_miles),\n",
    "          ebikeride_miles=lambda df_: df_['ebikeride'].map(meters_to_miles),\n",
    "          running_miles=lambda df_: df_['running'].map(meters_to_miles))\n",
    "  .set_index('year')\n",
    "  .loc[:, ['cycling_miles', 'ebikeride_miles', 'running_miles']]\n",
    "  .plot.bar(ax=ax, width=.9, color=[color_map[col] for \n",
    "                   col in ['cycling_miles', 'ebikeride_miles', 'running_miles']])\n",
    ")\n",
    "\n",
    "# hide legend\n",
    "ax.legend().set_visible(False)\n",
    "\n",
    "# get rid of spines\n",
    "for side in ['top', 'right', 'left', 'bottom']:\n",
    "    ax.spines[side].set_visible(False)\n",
    "\n",
    "# get rid of ticks\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "# rotate x labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "# set x tick label font and size\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_fontname(font)\n",
    "    label.set_fontsize(6)\n",
    "\n",
    "# clear x label\n",
    "ax.set_xlabel('')\n",
    "\n",
    "# get rid of y tick labels\n",
    "ax.set_yticklabels([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E - explain with title and subtitle and annotations\n",
    "import highlight_text as ht\n",
    "\n",
    "font = 'Roboto Condensed'\n",
    "\n",
    "LIGHT_BLUE = '#aec7e8'\n",
    "BLUE = '#1f77b4'\n",
    "GREEN = '#2da12c'\n",
    "LIGHT_ORANGE = '#fdbc79'\n",
    "ORANGE = '#ff7f0e'\n",
    "WHITE = '#ffffff'\n",
    "\n",
    "color_map = {'cycling_miles': LIGHT_BLUE,\n",
    "             'ebikeride_miles': GREEN, \n",
    "             'running_miles': LIGHT_ORANGE\n",
    "             }\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "\n",
    "\n",
    "(strava\n",
    "  .assign(cycling_miles=lambda df_: df_['cycling'].map(meters_to_miles),\n",
    "          ebikeride_miles=lambda df_: df_['ebikeride'].map(meters_to_miles),\n",
    "          running_miles=lambda df_: df_['running'].map(meters_to_miles))\n",
    "  .set_index('year')\n",
    "  .loc[:, ['cycling_miles', 'ebikeride_miles', 'running_miles']]\n",
    "  # horizontal lines require us to set zorder\n",
    "  .plot.bar(zorder=2, ax=ax, width=.9, color=[color_map[col] for \n",
    "                   col in ['cycling_miles', 'ebikeride_miles', 'running_miles']])\n",
    ")\n",
    "\n",
    "# hide legend\n",
    "ax.legend().set_visible(False)\n",
    "\n",
    "# get rid of spines\n",
    "for side in ['top', 'right', 'left', 'bottom']:\n",
    "    ax.spines[side].set_visible(False)\n",
    "\n",
    "# get rid of ticks\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "# rotate x labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "# set x tick label font and size\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_fontname(font)\n",
    "    label.set_fontsize(6)\n",
    "\n",
    "# clear x label\n",
    "ax.set_xlabel('')\n",
    "\n",
    "\n",
    "# make horizontal grid lines\n",
    "ax.yaxis.set_ticks([0, 200, 400, 600, 800])\n",
    "# add miles to just 800\n",
    "ax.set_yticklabels([0, 200, 400, 600, '800 miles'], font=font, fontsize=6,\n",
    "                   ha='right', va='bottom')\n",
    "# move y tick labels to right\n",
    "ax.yaxis.tick_right()\n",
    "# move y tick labels inside axes\n",
    "ax.tick_params(axis='y', pad=0)\n",
    "\n",
    "# set x limit to a little wider\n",
    "#print(ax.get_xlim())\n",
    "ax.set_xlim(0, 9)\n",
    "\n",
    "ax.yaxis.grid(True, color='grey', linestyle='-', linewidth=.5, zorder=0)\n",
    "\n",
    "bboxprops = {'linewidth': 0, 'pad': 1.5}\n",
    "\n",
    "ht.fig_text(fig=fig, x=0.2, y=0.815, ha='left',\n",
    "    s='E-Biking Uptake in 2023\\n<Miles ridden> <E-Biking>  <Cycling>  <Running>', font=font,\n",
    "    highlight_textprops=[\n",
    "        {'fontsize':10},\n",
    "        {'color': WHITE, 'fontsize':10,  \"bbox\": {\"facecolor\": GREEN, **bboxprops}} ,\n",
    "        {'color': WHITE, 'fontsize':10,  \"bbox\": {\"facecolor\": BLUE, **bboxprops}} ,\n",
    "        {'color': WHITE, 'fontsize':10,  \"bbox\": {\"facecolor\": ORANGE, **bboxprops}}] ,\n",
    "                           fontsize=16)\n",
    "\n",
    "# annotate 2020 as year started riding with team\n",
    "ax.annotate('Joined HS\\nMTB Team', xy=(.44, .5), xytext=(.6, 0.5), font=font,\n",
    "            xycoords='axes fraction', textcoords='axes fraction',\n",
    "            arrowprops=dict(facecolor='black', arrowstyle='-'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A - audience - who is this for?\n",
    "# R - references - add to bottom\n",
    "import highlight_text as ht\n",
    "\n",
    "font = 'Roboto Condensed'\n",
    "\n",
    "LIGHT_BLUE = '#aec7e8'\n",
    "BLUE = '#1f77b4'\n",
    "GREEN = '#2da12c'\n",
    "LIGHT_ORANGE = '#fdbc79'\n",
    "ORANGE = '#ff7f0e'\n",
    "WHITE = '#ffffff'\n",
    "\n",
    "color_map = {'cycling_miles': LIGHT_BLUE,\n",
    "             'ebikeride_miles': GREEN, \n",
    "             'running_miles': LIGHT_ORANGE\n",
    "             }\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "\n",
    "\n",
    "(strava\n",
    "  .assign(cycling_miles=lambda df_: df_['cycling'].map(meters_to_miles),\n",
    "          ebikeride_miles=lambda df_: df_['ebikeride'].map(meters_to_miles),\n",
    "          running_miles=lambda df_: df_['running'].map(meters_to_miles))\n",
    "  .set_index('year')\n",
    "  .loc[:, ['cycling_miles', 'ebikeride_miles', 'running_miles']]\n",
    "  # horizontal lines require us to set zorder\n",
    "  .plot.bar(zorder=2, ax=ax, width=.8, color=[color_map[col] for \n",
    "                   col in ['cycling_miles', 'ebikeride_miles', 'running_miles']])\n",
    ")\n",
    "\n",
    "# hide legend\n",
    "ax.legend().set_visible(False)\n",
    "\n",
    "# get rid of spines\n",
    "for side in ['top', 'right', 'left', 'bottom']:\n",
    "    ax.spines[side].set_visible(False)\n",
    "\n",
    "# get rid of ticks\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "# rotate x labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "# set x tick label font and size\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_fontname(font)\n",
    "    label.set_fontsize(6)\n",
    "\n",
    "# clear x label\n",
    "ax.set_xlabel('')\n",
    "\n",
    "# make horizontal grid lines\n",
    "ax.yaxis.set_ticks([0, 200, 400, 600, 800])\n",
    "# add miles to just 800\n",
    "ax.set_yticklabels([0, 200, 400, 600, '800 miles'], font=font, fontsize=6,\n",
    "                   ha='right', va='bottom')\n",
    "# move y tick labels to right\n",
    "ax.yaxis.tick_right()\n",
    "# move y tick labels inside axes\n",
    "ax.tick_params(axis='y', pad=0)\n",
    "\n",
    "# set x limit to a little wider\n",
    "#print(ax.get_xlim())\n",
    "ax.set_xlim(-0.65, 9)\n",
    "\n",
    "ax.yaxis.grid(True, color='grey', linestyle='-', linewidth=.5, zorder=0)\n",
    "\n",
    "bboxprops = {'linewidth': 0, 'pad': 1.5}\n",
    "\n",
    "ht.fig_text(fig=fig, x=0.2, y=0.815, ha='left',\n",
    "    s='E-Biking Uptake in 2023\\n<Miles ridden> <E-Biking>  <Cycling>  <Running>', font=font,\n",
    "    highlight_textprops=[\n",
    "        {'fontsize':10},\n",
    "        {'color': WHITE, 'fontsize':10,  \"bbox\": {\"facecolor\": GREEN, **bboxprops}} ,\n",
    "        {'color': WHITE, 'fontsize':10,  \"bbox\": {\"facecolor\": BLUE, **bboxprops}} ,\n",
    "        {'color': WHITE, 'fontsize':10,  \"bbox\": {\"facecolor\": ORANGE, **bboxprops}}] ,\n",
    "                           fontsize=16)\n",
    "\n",
    "# annotate 2020 as year started riding with team\n",
    "ax.annotate('Joined HS\\nMTB Team', xy=(.47, .5), xytext=(.6, 0.5), font=font,\n",
    "            xycoords='axes fraction', textcoords='axes fraction',\n",
    "            arrowprops=dict(facecolor='black', arrowstyle='-'))\n",
    "\n",
    "# add strava reference to bottom\n",
    "ht.fig_text(fig=fig, x=0.1, y=0.05, ha='left',\n",
    "            s='Source: Strava', font=font, fontsize=6)\n",
    "fig.savefig('strava.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try stacked\n",
    "import highlight_text as ht\n",
    "\n",
    "font = 'Roboto Condensed'\n",
    "\n",
    "LIGHT_BLUE = '#aec7e8'\n",
    "BLUE = '#1f77b4'\n",
    "GREEN = '#2da12c'\n",
    "LIGHT_ORANGE = '#fdbc79'\n",
    "ORANGE = '#ff7f0e'\n",
    "WHITE = '#ffffff'\n",
    "\n",
    "color_map = {'cycling_miles': LIGHT_BLUE,\n",
    "             'ebikeride_miles': GREEN, \n",
    "             'running_miles': LIGHT_ORANGE\n",
    "             }\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "(strava\n",
    "  .assign(cycling_miles=lambda df_: df_['cycling'].map(meters_to_miles),\n",
    "          ebikeride_miles=lambda df_: df_['ebikeride'].map(meters_to_miles),\n",
    "          running_miles=lambda df_: df_['running'].map(meters_to_miles))\n",
    "  .set_index('year')\n",
    "  #.loc[:, ['cycling_miles', 'ebikeride_miles', 'running_miles']]\n",
    "  .loc[:, [ 'running_miles', 'cycling_miles',  'ebikeride_miles',]]\n",
    "  # horizontal lines require us to set zorder\n",
    "  # use .pipe to get current order of columns\n",
    "    .pipe(lambda df_: df_\n",
    "  .plot.bar(zorder=2, ax=ax, width=.8, stacked=True,\n",
    "             color=[color_map[col] for \n",
    "                   col in df_.columns])\n",
    "    )\n",
    ")\n",
    "\n",
    "# hide legend\n",
    "ax.legend().set_visible(False)\n",
    "\n",
    "# get rid of spines\n",
    "for side in ['top', 'right', 'left', 'bottom']:\n",
    "    ax.spines[side].set_visible(False)\n",
    "\n",
    "# get rid of ticks\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "# rotate x labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "# set x tick label font and size\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_fontname(font)\n",
    "    label.set_fontsize(6)\n",
    "\n",
    "# clear x label\n",
    "ax.set_xlabel('')\n",
    "\n",
    "\n",
    "# make horizontal grid lines\n",
    "ax.yaxis.set_ticks([0, 200, 400, 600, 800])\n",
    "# add miles to just 800\n",
    "ax.set_yticklabels([0, 200, 400, 600, '800 miles'], font=font, fontsize=6,\n",
    "                   ha='right', va='bottom')\n",
    "# move y tick labels to right\n",
    "ax.yaxis.tick_right()\n",
    "# move y tick labels inside axes\n",
    "ax.tick_params(axis='y', pad=0)\n",
    "\n",
    "# set x limit to a little wider\n",
    "print(ax.get_xlim())\n",
    "ax.set_xlim(-0.65, 9.2)\n",
    "\n",
    "ax.yaxis.grid(True, color='grey', linestyle='-', linewidth=.5, zorder=0)\n",
    "\n",
    "bboxprops = {'linewidth': 0, 'pad': 1.5}\n",
    "\n",
    "ht.fig_text(fig=fig, x=0.2, y=0.815, ha='left',\n",
    "    s='E-Biking Uptake in 2023\\n<Miles ridden> <E-Biking>  <Cycling>  <Running>', font=font,\n",
    "    highlight_textprops=[\n",
    "        {'fontsize':10},\n",
    "        {'color': WHITE, 'fontsize':10,  \"bbox\": {\"facecolor\": GREEN, **bboxprops}} ,\n",
    "        {'color': WHITE, 'fontsize':10,  \"bbox\": {\"facecolor\": BLUE, **bboxprops}} ,\n",
    "        {'color': WHITE, 'fontsize':10,  \"bbox\": {\"facecolor\": ORANGE, **bboxprops}}] ,\n",
    "                           fontsize=16)\n",
    "\n",
    "# annotate 2020 as year started riding with team\n",
    "ax.annotate('Joined HS\\nMTB Team', xy=(.494, .5), xytext=(.6, 0.5), font=font,\n",
    "            xycoords='axes fraction', textcoords='axes fraction',\n",
    "            arrowprops=dict(facecolor='black', arrowstyle='-'))\n",
    "\n",
    "# add strava reference to bottom\n",
    "ht.fig_text(fig=fig, x=0.1, y=0.05, ha='left',\n",
    "            s='Source: Strava', font=font, fontsize=6)\n",
    "fig.savefig('strava-stack.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "url = 'https://github.com/mattharrison/datasets/raw/' \\\n",
    "   'refs/heads/master/data/vehicles.csv.zip'\n",
    "raw_mpg = pd.read_csv(url)\n",
    "raw_mpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_mpg.plot.scatter(x='displ', y='city08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def update_scatter(alpha, size):\n",
    "    # Plot the scatter with the current alpha and size values\n",
    "    raw_mpg.plot.scatter(x='displ', y='city08', alpha=alpha, s=size)\n",
    "    plt.show()\n",
    "\n",
    "# Create sliders for alpha and size\n",
    "alpha_slider = widgets.FloatSlider(\n",
    "    value=0.8, min=0.0, max=1.0, step=0.05, description='Alpha:'\n",
    ")\n",
    "size_slider = widgets.IntSlider(\n",
    "    value=50, min=1, max=60, #step=90, \n",
    "    description='Size:'\n",
    ")\n",
    "\n",
    "# Link the sliders to the update_scatter function\n",
    "interact(update_scatter, alpha=alpha_slider, size=size_slider);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "(raw_mpg\n",
    " .plot.scatter(x='displ', y='city08', s=2, alpha=.1, ax=ax,\n",
    "               title='City MPG vs Engine Displacement w/ alpha')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outlier & add jitter\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "\n",
    "def jitter(df, col, amount=1):\n",
    "    return df[col] + np.random.uniform(-amount, amount, size=len(df))\n",
    "\n",
    "(raw_mpg\n",
    " .query('displ > 0')\n",
    " .assign(displ=lambda df_: jitter(df_, 'displ', .1),\n",
    "         city08=lambda df_: jitter(df_, 'city08', 1))\n",
    " .plot.scatter(x='displ', y='city08', s=1, alpha=.05, ax=ax,\n",
    "               title='City MPG vs Engine Displacement (jittered)')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one col w/ 2 rows\n",
    "from scipy.optimize import curve_fit\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 4), dpi=300)\n",
    "\n",
    "\n",
    "def do_plots(fig, axs, raw_mpg):\n",
    "    (raw_mpg\n",
    "    .plot.scatter(x='displ', y='city08', s=2, alpha=.1, ax=axs[0],\n",
    "                title='City MPG vs Engine Displacement w/ alpha')\n",
    "    )\n",
    "    # curve fitting\n",
    "    def mpg_curve(x, a, b):\n",
    "        # note that we divide by x, so displ can't be 0!!!\n",
    "        return a/x + b\n",
    "\n",
    "    data = (raw_mpg\n",
    "            .query('(not displ.isna()) and (not city08.isna()) and (displ > 0)')\n",
    "    )\n",
    "\n",
    "    params, covariance = curve_fit(mpg_curve, data['displ'], data['city08'])\n",
    "    print(params)\n",
    "    x = np.linspace(0.2, 9, 1_000)\n",
    "    y = mpg_curve(x, *params)\n",
    "    axs[0].plot(x, y, color='red', linewidth=2)\n",
    "\n",
    "    # residuals in bottom plot\n",
    "    residuals = data['city08'] - mpg_curve(data['displ'], *params)\n",
    "    (raw_mpg\n",
    "    .assign(residuals=residuals)\n",
    "    .plot.scatter(x='displ', y='residuals', s=2, alpha=.1, ax=axs[1],\n",
    "                title='Residuals')\n",
    "    )\n",
    "    # draw horizontal line at 0\n",
    "    axs[1].axhline(0, color='gray', linewidth=2)\n",
    "    # set xlim to match top plot\n",
    "    axs[1].set_xlim(axs[0].get_xlim())\n",
    "    return fig, axs\n",
    "\n",
    "fig, axs = do_plots(fig, axs, raw_mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address overlappinng with tight_layout\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 4), dpi=300)\n",
    "fig, axs = do_plots(fig, axs, raw_mpg)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address overlappingn with constrained_layout\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 4), dpi=300, \n",
    "                        constrained_layout=True)\n",
    "fig, axs = do_plots(fig, axs, raw_mpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address overlappingn with manually adjusting padding\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 4), dpi=300)\n",
    "fig, axs = do_plots(fig, axs, raw_mpg)\n",
    "fig.subplots_adjust(left=.2, right=.9, top=.9, bottom=.1, \n",
    "                    wspace=.24, # horizontal (width) space between plots has no effect here\n",
    "                    hspace=.8 # vertical (height) space between plots\n",
    "                    )\n",
    "# .8 (80%) of vertical size of axes between plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address with GridSpec\n",
    "#fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 4), dpi=300)\n",
    "fig = plt.figure(figsize=(6, 4), dpi=300)\n",
    "gs = fig.add_gridspec(nrows=2, ncols=1, figure=fig,\n",
    "                      height_ratios=[2, 1],\n",
    "                      width_ratios=[1], # does nothing here\n",
    "                      hspace=.6\n",
    "                      )\n",
    "ax_top = fig.add_subplot(gs[0, 0])\n",
    "ax_bottom = fig.add_subplot(gs[1, 0])\n",
    "axs = [ax_top, ax_bottom]\n",
    "fig, axs = do_plots(fig, axs, raw_mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use subplot_mosaic\n",
    "layout = '''TTT\n",
    "            TTT\n",
    "            BBB'''\n",
    "fig, axes_dict = plt.subplot_mosaic(layout, figsize=(6, 4), dpi=300,\n",
    "    gridspec_kw={'hspace': 1.3},)\n",
    "top_axes = axes_dict['T']\n",
    "bottom_axes = axes_dict['B']\n",
    "fig, axs = do_plots(fig, [top_axes, bottom_axes], raw_mpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data\n",
    "\n",
    "Might crash Codespaces - Skip to next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_ratings = 'https://datasets.imdbws.com/title.ratings.tsv.gz'\n",
    "imdb_ratings_raw = pd.read_csv(url_ratings, sep='\\t', na_values=r'\\N')\n",
    "url_basics = 'https://datasets.imdbws.com/title.basics.tsv.gz'\n",
    "imdb_basics_raw = pd.read_csv(url_basics, sep='\\t', na_values=r'\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imdb_ratings_raw\n",
    " .merge(imdb_basics_raw, on='tconst')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_merged = (imdb_ratings_raw\n",
    "    .merge(imdb_basics_raw, on='tconst')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imdb_merged\n",
    " .loc[:, ['averageRating', 'startYear', 'titleType']]\n",
    " .to_parquet('data/imdb.parquet', index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_merged = pd.read_parquet('data/imdb.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imdb_merged\n",
    " .averageRating\n",
    " .plot.hist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imdb_merged\n",
    " .query('titleType == \"movie\"')\n",
    " .averageRating\n",
    " .plot.hist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(ncols=3, nrows=4, figsize=(6, 6))\n",
    "\n",
    "for i, bin in enumerate([2, 4, 6, 12, 19, 20, 40, 50, 60, 70, 100, 110]):\n",
    "    ax = axs.flat[i]\n",
    "    (imdb_merged\n",
    "    .query('titleType == \"movie\"')\n",
    "    .averageRating\n",
    "    .plot.hist(ax=ax, bins=bin, title=f'bins={bin}')\n",
    "    )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imdb_merged\n",
    " .query('titleType == \"movie\"')\n",
    " .averageRating\n",
    " .value_counts()\n",
    " .sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imdb_merged\n",
    " .query('titleType == \"movie\"')\n",
    " .averageRating\n",
    " .value_counts()\n",
    " .sort_index()\n",
    " .plot.bar(width=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    display(imdb_merged\n",
    " .query('titleType == \"movie\"')\n",
    " .averageRating\n",
    " .value_counts()\n",
    " .sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center the bins with numpy\n",
    "import numpy as np\n",
    "(imdb_merged\n",
    " .query('titleType == \"movie\"')\n",
    " #.query('averageRating.between(1.9, 3.1)')\n",
    " .averageRating\n",
    " .plot.hist(bins=np.arange(-.05, 10.05, step=.1))\n",
    " #.plot.hist(bins=np.arange(0, 10.1, step=.1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "from random import randint, uniform\n",
    "\n",
    "\n",
    "def histogram_energy(series, bins):\n",
    "    \"\"\"Calculate the energy of a histogram with a given number of bins.\"\"\"\n",
    "    hist, _ = np.histogram(series, bins=bins, density=True)\n",
    "    unique_values = len(series.unique())\n",
    "    energy = -entropy(hist)\n",
    "    # Penalize bins exceeding unique values\n",
    "    if bins > unique_values:\n",
    "        energy += (bins - unique_values) ** 2  # Strong penalty\n",
    "    return energy\n",
    "\n",
    "def simulated_annealing(series, initial_bins=10, max_bins=50, iterations=1000, \n",
    "                        initial_temp=10, cooling_rate=0.99):\n",
    "    \"\"\"Optimize the number of histogram bins using simulated annealing.\"\"\"\n",
    "    current_bins = initial_bins\n",
    "    current_energy = histogram_energy(series, current_bins)\n",
    "    best_bins = current_bins\n",
    "    best_energy = current_energy\n",
    "    temp = initial_temp\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # Generate a new solution (neighbor)\n",
    "        new_bins = current_bins + randint(-3, 3)\n",
    "        # Ensure bins are within valid range\n",
    "        new_bins = max(1, min(new_bins, max_bins)) \n",
    "\n",
    "        # Evaluate new solution\n",
    "        new_energy = histogram_energy(series, new_bins)\n",
    "\n",
    "        # Decide whether to accept the new solution\n",
    "        if ((new_energy < current_energy) or \n",
    "            (uniform(0, 1) < np.exp((current_energy - new_energy) / temp))):\n",
    "            current_bins = new_bins\n",
    "            current_energy = new_energy\n",
    "\n",
    "        # Update the best solution found\n",
    "        if new_energy < best_energy:\n",
    "            best_bins = new_bins\n",
    "            best_energy = new_energy\n",
    "\n",
    "        # Cool down\n",
    "        temp *= cooling_rate\n",
    "\n",
    "    return best_bins, best_energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, energy = simulated_annealing(imdb_merged\n",
    " .query('titleType == \"movie\"')\n",
    " .averageRating,\n",
    " max_bins=150,\n",
    ")\n",
    "print(bins, energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imdb_merged\n",
    " .query('titleType == \"movie\"')\n",
    " .averageRating\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have ratings changed since 2010?\n",
    "# Here is the data\n",
    "imdb_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have ratings changed since 2010?\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "(imdb_merged\n",
    " .query('titleType == \"movie\" and startYear >= 2010')\n",
    " .averageRating\n",
    " .plot.hist(bins=np.arange(-.05, 10.05, step=.1), ax=ax)\n",
    ")\n",
    "(imdb_merged\n",
    " .query('titleType == \"movie\" and startYear < 2010')\n",
    " .averageRating\n",
    " .plot.hist(bins=np.arange(-.05, 10.05, step=.1), ax=ax, alpha=.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "(imdb_merged\n",
    " .query('titleType == \"movie\" and startYear >= 2010')\n",
    " .averageRating\n",
    " .plot.hist(bins=np.arange(-.05, 10.05, step=.1), ax=ax,\n",
    "            density=True, alpha=.5, label='2010+')\n",
    ")\n",
    "(imdb_merged\n",
    " .query('titleType == \"movie\" and startYear < 2010')\n",
    " .averageRating\n",
    " .plot.hist(bins=np.arange(-.05, 10.05, step=.1), ax=ax,\n",
    "            density=True, alpha=.5, label='pre-2010')\n",
    ")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get quantiles (0%, 5%, 10%, ..., 100%)\n",
    "(imdb_merged\n",
    " .query('titleType == \"movie\" and startYear >= 2010')\n",
    " .averageRating\n",
    " .quantile(np.linspace(0, 1, 21))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get quantiles\n",
    "(imdb_merged\n",
    " .query('titleType == \"movie\" and startYear < 2010')\n",
    " .averageRating\n",
    " .quantile(np.linspace(0, 1, 21))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot quantiles of 2010+ vs pre-2010\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "q2010 = (imdb_merged\n",
    " .query('titleType == \"movie\" and startYear >= 2010')\n",
    " .averageRating\n",
    " .quantile(np.linspace(0, 1, 21))\n",
    ")\n",
    "\n",
    "qpre2010 = (imdb_merged\n",
    "    .query('titleType == \"movie\" and startYear < 2010')\n",
    "    .averageRating\n",
    "    .quantile(np.linspace(0, 1, 21))\n",
    "    )\n",
    "\n",
    "ax.scatter(q2010, q2010.index, label='2010+')\n",
    "ax.scatter(qpre2010, qpre2010.index, label='pre-2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAR\n",
    "# color - adjust alpha\n",
    "# limited plot - scatter, get rid of spines, etc\n",
    "# explain - title, subtitle, annotations\n",
    "# audience - who is this for?\n",
    "# references - add to bottom\n",
    "import highlight_text as ht\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "BLUE = '#1f77b4'\n",
    "GREEN = '#2ca02c'\n",
    "FONT = 'Roboto Condensed'\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "q2010 = (imdb_merged\n",
    " .query('titleType == \"movie\" and startYear >= 2010')\n",
    " .averageRating\n",
    " .quantile(np.linspace(0, 1, 21))\n",
    ")\n",
    "\n",
    "qpre2010 = (imdb_merged\n",
    "    .query('titleType == \"movie\" and startYear < 2010')\n",
    "    .averageRating\n",
    "    .quantile(np.linspace(0, 1, 21))\n",
    "    )\n",
    "\n",
    "ax.scatter(q2010, q2010.index, label='2010+', alpha=1, c=BLUE)\n",
    "ax.scatter(qpre2010, qpre2010.index, label='pre-2010', alpha=.7, c=GREEN)\n",
    "# connect with lines\n",
    "for idx in q2010.index:\n",
    "    ax.plot([q2010.loc[idx], qpre2010.loc[idx]], [idx, idx], \n",
    "            zorder=-1, color='gray', alpha=.5)\n",
    "\n",
    "# get rid of spines\n",
    "for side in ['top', 'right', 'left', #'bottom'\n",
    "             ]:\n",
    "    ax.spines[side].set_visible(False)\n",
    "# move y ticks to right\n",
    "ax.yaxis.tick_right()\n",
    "# use line instead of ticks\n",
    "ax.tick_params(axis='y', length=0)\n",
    "ax.yaxis.grid(True, color='gray', linestyle='-', linewidth=.25)\n",
    "# set y ticks and font\n",
    "ax.set_yticks(np.arange(0, 1.1, .1))\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontname(FONT)\n",
    "    label.set_fontsize(6)\n",
    "    label.set_ha('right')\n",
    "    label.set_va('bottom')\n",
    "# set formatter for y labels use function to make %\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{x:.0%}'))\n",
    "# move labels on top of line\n",
    "\n",
    "# set limits\n",
    "ax.set_xlim(0, 11)\n",
    "\n",
    "# set x tick labels and font\n",
    "ax.set_xticks(np.arange(1, 11, 1))\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_fontname(FONT)\n",
    "    label.set_fontsize(6)\n",
    "\n",
    "# add title and subtitle with highlight_text use colors instead of legend\n",
    "ht.fig_text(fig=fig, x=0.1, y=0.95, ha='left',\n",
    "            s='Rating Quantiles: <2010+> vs <pre-2010>\\n'\n",
    "            '<After 30%, 2010+ movies get better ratings>', font=FONT,\n",
    "            highlight_textprops=[{'color': BLUE, 'fontsize':14},\n",
    "                                 {'color': GREEN, 'fontsize':14},\n",
    "                                 {'fontsize':8}], fontsize=12)\n",
    "\n",
    "# annotate 80% quantile\n",
    "ax.annotate('Top 80% of 2010+ Movies\\nhave .5 better rating', \n",
    "            xy=(7.61, .8), xytext=(7, .4), fontname=FONT,\n",
    "            xycoords='data', textcoords='data',\n",
    "            arrowprops=dict(facecolor='black', arrowstyle='-'))\n",
    "\n",
    "# add source\n",
    "ht.fig_text(fig=fig, x=0.1, y=0.02, ha='left',\n",
    "            s='Source: IMDB', font=FONT, fontsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Notice what happens when you see a plot\n",
    "- Use the CLEAR methodology\n",
    "- Practice\n",
    "- Share. I would love to see your plots!\n",
    "- Reach out if your team needs help with tabular data. (matt@metasnake.com)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
